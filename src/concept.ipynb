{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "- Get line by using cv2 to detect lines and connections between nodes\n",
    "- nodes will always be in the same locations, ROI will not change\n",
    "- Find contours is too complex to use, need to simplify to reduce room of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import preprocess\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, th_1=50, th_2=200):\n",
    "    img_canny = cv.Canny(img, th_1, th_2)\n",
    "\n",
    "    return img_canny\n",
    "\n",
    "def blur_and_canny(img):\n",
    "    blurred = cv.GaussianBlur(img, (7,7), 1)\n",
    "    canny = cv.Canny(blurred, 120, 255, 1)\n",
    "\n",
    "    return canny\n",
    "\n",
    "def crop_image(img: cv.Mat) -> cv.Mat:\n",
    "    height, width = img.shape\n",
    "\n",
    "    min_height = int(0.3*height)\n",
    "    max_height = int(0.85*height)\n",
    "    min_width = int(0.3*width)\n",
    "\n",
    "    cropped_image = img[min_height:max_height, min_width:width]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def resize_image(img: cv.Mat, width=1280, height=720) -> cv.Mat:\n",
    "    resized = cv.resize(img, (width, height))\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = cv.imread(\"../images/dungeon2.png\")\n",
    "img_original = cv.cvtColor(img_original, cv.COLOR_BGR2RGB)\n",
    "img = cv.cvtColor(img_original, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "img = crop_image(img)\n",
    "img = preprocess.blur(img, (1,1))\n",
    "ret, img = cv.threshold(img, 55, 255, cv.THRESH_BINARY)\n",
    "img = canny(img)\n",
    "contours, hierarchy = cv.findContours(img, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv.drawContours(img_original, contours, -1, (255,0,0), 1)\n",
    "approxes = []\n",
    "for i, cnt in enumerate(contours):\n",
    "    epsilon = 0.05*cv.arcLength(cnt,True)\n",
    "    approx = cv.approxPolyDP(cnt,epsilon,True)\n",
    "    if len(approx) == 3:\n",
    "        approxes.append(cnt)\n",
    "        cv.drawContours(img_original, [cnt], 0, (0,255,0), 2)\n",
    "print(len(approxes))\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(img_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Nodes():\n",
    "    x_start: int = 700\n",
    "    y_start: int = 380\n",
    "    width: int = 60\n",
    "    height: int = 60\n",
    "    x_stride: int = 160\n",
    "    y_stride: int = 130\n",
    "\n",
    "@dataclass\n",
    "class Node():\n",
    "    name: str\n",
    "    x: int \n",
    "    y: int \n",
    "    width: int \n",
    "    height: int \n",
    "    connection: list[\"Node\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 690\n",
    "y_start = 370\n",
    "\n",
    "width = 80\n",
    "height = 80\n",
    "\n",
    "x_stride = 160\n",
    "y_stride = 130\n",
    "\n",
    "param = Nodes()\n",
    "\n",
    "nodes = []\n",
    "index = 1\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        name = f\"Node_{index}\"\n",
    "        node = Node(name, x_start, y_start, width, height, connection=[])\n",
    "        nodes.append(node)\n",
    "\n",
    "        y_start = y_start + y_stride\n",
    "        index = index + 1\n",
    "    y_start = 370\n",
    "    x_start = x_start + x_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = cv.imread(\"../images/train_1.png\")\n",
    "img_original = cv.cvtColor(img_original, cv.COLOR_BGR2RGB)\n",
    "# img = img_original\n",
    "img = cv.cvtColor(img_original, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "# img = cv.add(img, 50)\n",
    "# img = preprocess.blur(img, (3,3))\n",
    "# ret, img = cv.threshold(img, 55, 255, cv.THRESH_BINARY)\n",
    "# img = canny(img)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16,8))\n",
    "index = 0\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        node = nodes[index]\n",
    "        axes[j,i].set_title(node.name)\n",
    "        axes[j,i].imshow(img[node.y:node.y+node.height, node.x:node.x+node.width], cmap='gray')\n",
    "        index = index + 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_detection import detect_feature, match_feature\n",
    "import os\n",
    "\n",
    "dir = \"D:\\Repository\\python-limbus\\images\\encounter\"\n",
    "queries = []\n",
    "predictions = []\n",
    "for file in os.listdir(dir):\n",
    "    q = cv.imread(f\"{dir}\\\\{file}\", cv.IMREAD_GRAYSCALE)\n",
    "    kp, desc = detect_feature(q, edge_threshold=10)\n",
    "    query = {\n",
    "        \"name\": file.split(\".\")[0],\n",
    "        \"img\": q,\n",
    "        \"keypoints\": kp,\n",
    "        \"descriptor\": desc\n",
    "    }\n",
    "    queries.append(query)\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    node_location = img[node.y:node.y+node.height, node.x:node.x+node.width]\n",
    "    kp, desc = detect_feature(node_location, edge_threshold=10)\n",
    "    print(i+1)\n",
    "\n",
    "    if desc is None: \n",
    "        continue\n",
    "    \n",
    "    pred = {\"name\":\"\", \"min\":0}\n",
    "    for query in queries:\n",
    "        matches = match_feature(query[\"descriptor\"], desc, True)\n",
    "        top_ten = [match.distance for match in matches[:10]]\n",
    "\n",
    "        if pred[\"min\"] == 0:\n",
    "            pred[\"name\"] = query[\"name\"]\n",
    "            pred[\"min\"] = mean(top_ten)\n",
    "        elif pred[\"min\"] > mean(top_ten):\n",
    "            pred[\"name\"] = query[\"name\"]\n",
    "            pred[\"min\"] = mean(top_ten)\n",
    "\n",
    "    print(pred[\"name\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = queries[3]\n",
    "\n",
    "node = nodes[-1]\n",
    "img2 = img[node.y:node.y+node.height, node.x:node.x+node.width]\n",
    "kp2, desc2 = detect_feature(img2)\n",
    "\n",
    "matches = match_feature(img1[\"descriptor\"], desc2, True)\n",
    "print(mean([match.distance for match in matches[:10]]))\n",
    "img_match = cv.drawMatches(img1[\"img\"], img1[\"keypoints\"], img2, kp2, matches[:10], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.imshow(img_match)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = cv.imread(\"../images/train_1.png\")\n",
    "img_original = cv.cvtColor(img_original, cv.COLOR_BGR2RGB)\n",
    "img = cv.cvtColor(img_original, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from limbus.data import Encounters, Config\n",
    "from limbus.dungeon import Dungeon\n",
    "import cv2 as cv\n",
    "\n",
    "dir = \"D:\\Repository\\python-limbus\\images\\encounter\"\n",
    "dungeon_map = \"D:\\Repository\\python-limbus\\images\\\\train_1.png\"\n",
    "map = cv.imread(dungeon_map, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "cfg = Config()\n",
    "md = Dungeon(map, config=cfg, encounters_dir=dir)\n",
    "\n",
    "nodes = md.map()\n",
    "connections = md.map_connections()\n",
    "\n",
    "connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from math import dist\n",
    "\n",
    "img_dir = \"D:\\Repository\\python-limbus\\images\\\\train_1.png\"\n",
    "\n",
    "img = cv.imread(img_dir, cv.IMREAD_GRAYSCALE)\n",
    "img = cv.GaussianBlur(img, (3,3), 0)\n",
    "img = cv.Canny(img, 15, 75)\n",
    "# img = cv.add(img, 50)\n",
    "\n",
    "# img_1 = img[360:750, 730:880] # 150\n",
    "# img_2 = img[360:750, 890:1040] # 150\n",
    "# img_3 = img[360:750, 1050:1200] # 150\n",
    "\n",
    "img_1 = img[nodes[0].y:nodes[2].y+nodes[2].height, nodes[0].x+nodes[0].width:nodes[3].x] \n",
    "img_2 = img[nodes[0].y:nodes[2].y+nodes[2].height, nodes[3].x+nodes[3].width:nodes[6].x]\n",
    "img_3 = img[nodes[0].y:nodes[2].y+nodes[2].height, nodes[6].x+nodes[6].width:nodes[9].x]\n",
    "\n",
    "# rho = 1  # distance resolution in pixels of the Hough grid\n",
    "# theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "# threshold = 50  # minimum number of votes (intersections in Hough grid cell)\n",
    "# min_line_length = 75  # minimum number of pixels making up a line\n",
    "# max_line_gap = 30  # maximum gap in pixels between connectable line segments\n",
    "\n",
    "kwargs = {\n",
    "    \"rho\": 1,\n",
    "    \"theta\": np.pi / 180,\n",
    "    \"threshold\": 50,\n",
    "    \"minLineLength\": 25,\n",
    "    \"maxLineGap\": 50\n",
    "}\n",
    "\n",
    "def check_duplicate(index: int, lines: list, min_distance: int=50) -> bool:\n",
    "    has_duplicate = False\n",
    "    query = lines[index]\n",
    "\n",
    "    min_dst = float(\"inf\")\n",
    "    for i in range(0, index):\n",
    "        dst = dist(query.reshape(-1), lines[i].reshape(-1))\n",
    "\n",
    "        if dst < min_dst:\n",
    "            min_dst = dst\n",
    "    \n",
    "    if min_dst < min_distance:\n",
    "        has_duplicate = True\n",
    "\n",
    "    return has_duplicate\n",
    "\n",
    "imgs = [img_1, img_2, img_3]\n",
    "for img in imgs:\n",
    "    lines = cv.HoughLinesP(img, **kwargs)\n",
    "    for i, line in enumerate(lines):\n",
    "        has_dupe = check_duplicate(i, lines, 50)\n",
    "        if has_dupe is False:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv.line(img, (x1,y1), (x2,y2), (255,0,0), 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16,8))\n",
    "for i, img in enumerate(imgs):\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{nodes[0]}\")\n",
    "print(f\"{nodes[3]}\")\n",
    "print(f\"{nodes[6]}\")\n",
    "\n",
    "for i in range(0,7,3):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            x = nodes[i].x + nodes[i].width + x1\n",
    "            y = nodes[i].y + y1\n",
    "            xt = nodes[i].x + nodes[i].width + x2\n",
    "            yt = nodes[i].y + y2\n",
    "            \n",
    "            print(f\"Position:\\t\\tActual:\")\n",
    "            print(f\"{line}\\t\\t{[[x, y, xt, yt]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
